<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>RAG Pipeline Simulator - Verified</title>
    <style>
        :root { --primary: #4a90e2; --bg: #f8f9fa; --success: #27ae60; }
        body { font-family: 'Segoe UI', sans-serif; background: var(--bg); padding: 20px; display: flex; flex-direction: column; align-items: center; }
        .container { max-width: 1100px; width: 100%; display: grid; grid-template-columns: 1.2fr 0.8fr; gap: 20px; }
        .card { background: white; padding: 25px; border-radius: 12px; box-shadow: 0 4px 15px rgba(0,0,0,0.05); margin-bottom: 20px; }
        #doc-view { line-height: 1.8; padding: 20px; border: 1px solid #ddd; border-radius: 8px; background: #fff; white-space: pre-wrap; font-size: 1.05rem; }
        .chunk-0 { background: #ffadad; } .chunk-1 { background: #ffd6a5; } .chunk-2 { background: #fdffb6; }
        .winner { outline: 4px solid var(--success); box-shadow: 0 0 15px rgba(39, 174, 96, 0.5); position: relative; z-index: 10; }
        .step { margin-bottom: 20px; padding: 15px; border-left: 4px solid #ddd; background: #fafafa; }
        .step.active { border-left-color: var(--primary); background: #f0f7ff; }
        .search-box { margin-top: 20px; padding: 20px; background: #eef2f7; border-radius: 8px; display: none; }
        input { width: 70%; padding: 10px; border-radius: 5px; border: 1px solid #ccc; }
        .btn-main { width: 100%; padding: 15px; background: var(--primary); color: white; border: none; border-radius: 8px; font-weight: bold; cursor: pointer; font-size: 1rem; }
        .btn-search { padding: 10px 20px; background: var(--success); color: white; border: none; border-radius: 5px; cursor: pointer; font-weight: bold; }
        .vector-preview { font-family: monospace; font-size: 0.75rem; color: #666; margin-top: 5px; display: block; }
        .ranking-item { display: flex; justify-content: space-between; padding: 5px 0; border-bottom: 1px solid #eee; font-size: 0.9rem; }

        .info-note { margin-top: 15px; padding: 10px; background-color: #fffbe6; border: 1px solid #ffe58f; border-radius: 4px; font-size: 0.8rem; color: #856404; }
        .query-vector { font-weight: bold; color: var(--primary); }
        .rewrite-box { color: #6a1b9a; font-style: italic; font-size: 0.85rem; margin-bottom: 10px; display: block; }

        .math-text { font-family: "Times New Roman", serif; font-size: 1rem; display: block; text-align: center; margin: 10px 0; font-weight: bold; }
        .fraction { display: inline-block; vertical-align: middle; text-align: center; margin: 0 5px; }
        .fraction span { display: block; padding: 0 2px; }
        .fraction .num { border-bottom: 1px solid #856404; }

        #llm-window {
            background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 8px;
            font-family: 'Consolas', monospace; font-size: 0.85rem; border: 1px solid #333;
            white-space: pre-wrap; margin-top: 10px; display: none;
        }
        .p-sys { color: #569cd6; font-weight: bold; }
        .p-ctx { color: #ce9178; font-weight: bold; }
        .p-user { color: #b5cea8; font-weight: bold; }
        .p-res { color: #4ec9b0; font-weight: bold; text-decoration: underline; }
        .warning-text { color: #f44336; font-weight: bold; }
    </style>
</head>
<body>

<h1>RAG Pipeline Simulator</h1>

<div class="container">
    <div class="card">
        <h2>1. Source Document & Search</h2>
        <div id="doc-view">Loading document...</div>
        <div id="search-area" class="search-box">
            <strong>Semantic Search (Phase 2):</strong><br><br>
            <input type="text" id="queryInput" placeholder="Ask a question (e.g. How are LLMs trained?)...">
            <button class="btn-search" onclick="runRetrieval()">Search</button>

            <div id="query-processing-area" style="display:none; margin-top:15px; padding-top:10px; border-top: 1px dashed #ccc;">
                <span id="rewritten-query" class="rewrite-box"></span>
                <span class="query-vector">Query Vector:</span>
                <span class="vector-preview" id="q-vec-display"></span>
            </div>

            <div class="info-note">
                <strong>Note on Query Expansion:</strong><br>
                Real RAG systems often "rewrite" your question into a detailed search query to find better matches in the database.
            </div>

            <p id="search-status" style="font-size: 0.85rem; color: #555; margin-top: 10px;"></p>
        </div>
    </div>

    <div class="card">
        <h2>Processing Status</h2>

        <div class="step" id="step-chunk">
            <strong>Stage A: Chunking</strong>
            <p id="chunk-meta">Waiting...</p>
            <div class="info-note">
                <strong>Semantic Chunking:</strong><br>
                Instead of cutting text at fixed intervals, we group text based on <strong>meaning</strong>. By ensuring each chunk covers a complete thought, the resulting vector is more precise and retrieval becomes more accurate.
            </div>
        </div>

        <div class="step" id="step-embed">
            <strong>Stage B: Embedding</strong>
            <div id="vector-list"></div>
            <div class="info-note">
                <strong>V<sub>chunk</sub> Representation:</strong><br>
                A single chunk contains many words, but is represented by only one vector. This vector is the <strong>mean pool</strong> (average) of every individual word vector within that chunk:
                <div class="math-text">
                    V<sub>chunk</sub> =
                    <div class="fraction">
                        <span class="num">1</span>
                        <span>n</span>
                    </div>
                    Σ V<sub>word<sub>i</sub></sub>
                </div>
                This "compresses" the collective meaning of the entire sentence into a single point in space.
            </div>
        </div>

        <div class="step" id="step-retrieve">
            <strong>Stage C: Semantic Retrieval</strong>
            <div id="ranking-list">Waiting for search...</div>

            <div class="info-note">
                <strong>Note on Vector Matching:</strong><br>
                Both the <strong>document chunks</strong> and your <strong>query</strong> are converted into vectors using the same embedding model. The system then compares the query vector to all chunk vectors to find the closest match.
            </div>

            <div class="info-note">
                <strong>Note on Similarity Scores:</strong><br>
                Even if a specific word is missing from a chunk, the system may still report a small similarity percentage (e.g., 5-8%) because vector math measures mathematical "closeness" in general meaning rather than just keyword presence.
            </div>
        </div>

        <div class="step" id="step-generate">
            <strong>Stage D: LLM Generation</strong>
            <div id="llm-window"></div>
            <div class="info-note" id="gen-note" style="display:none;">
                <strong>Similarity Threshold:</strong> If the best match is below 20%, the system triggers a safety response to prevent the AI from hallucinating based on irrelevant data.
            </div>
        </div>

        <button id="processBtn" class="btn-main" onclick="processDocument()">Process & Index Document</button>
    </div>
</div>

<script>
    const chunkData = [
        "The evolution of LLMs represents a significant leap in AI. Historically, NLP relied on simple statistical models. The introduction of the Transformer architecture in 2017 changed everything, allowing models to process entire sequences simultaneously.",
        "\n\nTraining involves feeding models billions of pages of text. During this process, the model learns statistical relationships between words. This enables it to predict the next token with accuracy.",
        "\n\nIn RAG systems, developers break documents into chunks. These chunks are stored in a vector database. When a user asks a question, the system retrieves only the most relevant chunks to provide context to the LLM."
    ];

    function init() {
        document.getElementById('doc-view').innerText = chunkData.join("");
    }

    function processDocument() {
        const docContainer = document.getElementById('doc-view');
        const vectorList = document.getElementById('vector-list');
        vectorList.innerHTML = "";
        docContainer.innerHTML = "";

        chunkData.forEach((text, i) => {
            const span = document.createElement('span');
            span.innerText = text;
            span.className = `chunk-${i}`;
            span.id = `chunk-span-${i}`;
            docContainer.appendChild(span);
            const vDiv = document.createElement('div');
            vDiv.innerHTML = `<strong>V${i+1}:</strong> <span class="vector-preview">[${Math.random().toFixed(3)}, ${Math.random().toFixed(3)}...]</span>`;
            vectorList.appendChild(vDiv);
        });

        document.getElementById('step-chunk').className = "step active";
        document.getElementById('chunk-meta').innerText = `Created ${chunkData.length} semantic chunks.`;
        document.getElementById('step-embed').className = "step active";
        document.getElementById('search-area').style.display = "block";
        document.getElementById('processBtn').style.display = "none";
    }

    function runRetrieval() {
        const query = document.getElementById('queryInput').value.trim();
        if(!query) return;

        document.getElementById('query-processing-area').style.display = "block";
        document.getElementById('rewritten-query').innerText = `✨ Expanded Query: "Find information related to ${query} and relevant AI concepts..."`;
        document.getElementById('q-vec-display').innerText = `[${Math.random().toFixed(3)}, ${Math.random().toFixed(3)}, ${Math.random().toFixed(3)}...]`;

        for(let i=0; i<chunkData.length; i++) {
            document.getElementById(`chunk-span-${i}`).classList.remove('winner');
        }

        let scores = chunkData.map(text => {
            if (text.toLowerCase().includes(query.toLowerCase()) ||
               (query.length > 5 && text.toLowerCase().split(' ').some(word => query.toLowerCase().includes(word) && word.length > 3))) {
                return 0.90 + (Math.random() * 0.09);
            }
            return 0.05 + (Math.random() * 0.05);
        });

        const winnerIdx = scores.indexOf(Math.max(...scores));
        const maxScore = scores[winnerIdx];

        document.getElementById('step-retrieve').className = "step active";

        if (maxScore > 0.20) {
            document.getElementById(`chunk-span-${winnerIdx}`).classList.add('winner');
            document.getElementById('search-status').innerText = `Matching Vector for expanded query... Success!`;
            runGeneration(query, chunkData[winnerIdx], true);
        } else {
            document.getElementById('search-status').innerText = `Low similarity score (${(maxScore*100).toFixed(0)}%). Retrieval discarded.`;
            runGeneration(query, "", false);
        }

        const rankingList = document.getElementById('ranking-list');
        rankingList.innerHTML = "<strong>Top Matches:</strong>";
        scores.forEach((s, i) => {
            rankingList.innerHTML += `<div class="ranking-item"><span>Chunk ${i+1}</span> <span>${(s*100).toFixed(0)}%</span></div>`;
        });
    }

    function runGeneration(query, context, hasContext) {
        document.getElementById('step-generate').className = "step active";
        const win = document.getElementById('llm-window');
        win.style.display = "block";
        document.getElementById('gen-note').style.display = "block";

        if (!hasContext) {
            win.innerHTML = `<span class="p-sys">SYSTEM:</span> You are a helpful assistant.
<span class="p-ctx">CONTEXT:</span> [EMPTY]
<span class="p-user">USER:</span> ${query}
<span class="p-res">AI RESPONSE:</span> <span class="warning-text">I do not have information in the provided document to answer that accurately.</span>`;
            return;
        }

        let response = "I'm sorry, I don't have enough information in the provided context.";
        if(context.includes("RAG")) response = "RAG systems use a retrieval-then-generation approach to provide contextually accurate answers.";
        if(context.includes("Transformer")) response = "The 2017 Transformer architecture is the foundation for modern LLMs, allowing parallel processing.";
        if(context.includes("Training")) response = "LLMs are trained on massive datasets to predict the most likely next word in a sequence.";

        win.innerHTML = `<span class="p-sys">SYSTEM:</span> Answer based on context.
<span class="p-ctx">CONTEXT:</span> ${context.trim()}
<span class="p-user">USER:</span> ${query}
<span class="p-res">AI RESPONSE:</span> ${response}`;
    }

    init();
</script>
</body>
</html>